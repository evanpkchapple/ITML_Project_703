{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "716e3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('TkAgg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "img_path = 'imgs/'\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, random_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "da73b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOW_token = 0\n",
    "EOW_token = 1\n",
    "\n",
    "class Chars:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.char2index = {}\n",
    "        self.char2count = {}\n",
    "        self.index2char = {0: \"SOW\", 1: \"EOW\"}\n",
    "        self.n_chars = 2\n",
    "\n",
    "    def addWord(self, word):\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2f5a8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readChars(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    #lang1 = 'spa'\n",
    "    #lang2 = 'fre'\n",
    "    path = lang1 + '_' + lang2\n",
    "    data_path = 'data/'+path+'.txt'\n",
    "\n",
    "    f = open(data_path, 'r')\n",
    "    source_words = []\n",
    "    target_words = []\n",
    "    pairs = []\n",
    "\n",
    "    for line in f:\n",
    "        word = line.strip().split('$')\n",
    "        pairs.append(word)\n",
    "        source_words.append(word[0])\n",
    "        target_words.append(word[1])\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Chars(lang2)\n",
    "        output_lang = Chars(lang1)\n",
    "    else:\n",
    "        input_lang = Chars(lang1)\n",
    "        output_lang = Chars(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6628e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readChars(lang1, lang2, reverse)\n",
    "    print(\"Read {} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting chars...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addWord(pair[0])\n",
    "        output_lang.addWord(pair[1])\n",
    "    print(\"Counted chars:\")\n",
    "    print(input_lang.name, input_lang.n_chars)\n",
    "    print(output_lang.name, output_lang.n_chars)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bb1ce842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 3369 sentence pairs\n",
      "Counting chars...\n",
      "Counted chars:\n",
      "spa 31\n",
      "fre 39\n",
      "['ɾeaktibos', 'ʁeaktif']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('spa', 'fre')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0a622cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH_INPUT = max(len(pair[0]) for pair in pairs)\n",
    "MAX_LENGTH_OUTPUT = max(len(pair[1]) for pair in pairs)\n",
    "MAX_LENGTH = max(MAX_LENGTH_INPUT, MAX_LENGTH_OUTPUT)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d1a3f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bdfb9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOW_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5d710ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOW_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) \n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "73a91bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromWord(lang, word):\n",
    "    return [lang.char2index[char] for char in word]\n",
    "\n",
    "def tensorFromWord(lang, word):\n",
    "    indexes = indexesFromWord(lang, word)\n",
    "    indexes.append(EOW_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromWord(input_lang, pair[0])\n",
    "    target_tensor = tensorFromWord(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('spa', 'fre')\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromWord(input_lang, inp)\n",
    "        tgt_ids = indexesFromWord(output_lang, tgt)\n",
    "        \n",
    "        inp_ids.append(EOW_token)\n",
    "        tgt_ids.append(EOW_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    all_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    #train_sampler = RandomSampler(train_data)\n",
    "    train_test_gen = torch.Generator().manual_seed(42)\n",
    "    train_data, test_data = random_split(all_data, [0.8, 0.2], generator=train_test_gen)\n",
    "    \n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    \n",
    "    test_sampler = RandomSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "    return input_lang, output_lang, train_dataloader, test_dataloader, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3daed1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "1734827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e7c5733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, test_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100, patience=5):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0 \n",
    "    plot_loss_total = 0 \n",
    "    \n",
    "    val_losses = []\n",
    "    validation_list = []\n",
    "    print_val_loss_total = 0\n",
    "    plot_val_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss() #try cross entropy?\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        start = time.time()\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        val_loss = validate(test_dataloader, encoder, decoder)\n",
    "\n",
    "        validation_list.append(val_loss)\n",
    "        \n",
    "        print_val_loss_total += val_loss\n",
    "        plot_val_loss_total += val_loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            \n",
    "            print_val_loss_avg = print_val_loss_total / print_every\n",
    "            print_val_loss_total = 0\n",
    "            \n",
    "            print('Epoch: {}/{},\\tTime Taken: {:.2f} seconds,\\tTraining Loss: {:.4f},\\tValidation Loss: {:.4f}'.format(epoch, n_epochs, time.time()-start, print_loss_avg, print_val_loss_avg))\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "            plot_val_loss_avg = plot_val_loss_total / plot_every\n",
    "            val_losses.append(plot_val_loss_avg)\n",
    "            plot_val_loss_total = 0\n",
    "\n",
    "        if len(validation_list) > patience+1 and val_loss > max(validation_list[(-1 * patience) - 1:-1]):\n",
    "            print(\"Validation loss has not gone down for \" + str(patience) + \" epochs. Implementing Early Stopping\")\n",
    "            break\n",
    "\n",
    "    showPlot(plot_losses, 'train_loss')\n",
    "    showPlot(val_losses, 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f3a99c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(test_dataloader, encoder, decoder):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for data in test_dataloader:\n",
    "    \n",
    "        input_tensor, target_tensor = data\n",
    "    \n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor) \n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    return total_loss/len(test_dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "df4fa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points, loss_type):\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    if loss_type == 'val_loss':\n",
    "        ax.plot(points, color='red')\n",
    "        ax.set_title(\"Validation Loss\")\n",
    "    else:\n",
    "        ax.plot(points)\n",
    "        ax.set_title(\"Training Loss\")\n",
    "    plt.savefig(img_path + loss_type + '.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "73b7f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, word, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        #input_tensor = tensorFromWord(input_lang, word)\n",
    "        input_tensor = word\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_chars = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOW_token:\n",
    "                decoded_chars.append('<EOW>')\n",
    "                break\n",
    "            decoded_chars.append(output_lang.index2char[idx.item()])\n",
    "        \n",
    "    return decoded_chars, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "98802f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_word, output_chars, correct_output, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.set_title(input_word + ' -> ' + correct_output)\n",
    "    \n",
    "    ax.set_xticklabels([''] + [*input_word] +\n",
    "                       ['<EOW>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_chars)\n",
    "    \n",
    "    ax.set(xlim=(0, len(input_word)+1))\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.savefig(img_path+input_word+'_attention.png', bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a3eb8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        random_index = random.randint(0, len(test_data))\n",
    "        pair = test_data.dataset[random_index]\n",
    "        pair = (torch.unsqueeze(pair[0], 0), torch.unsqueeze(pair[1], 0))\n",
    "        \n",
    "        output_chars, attentions = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_word = ''.join(output_chars)\n",
    "        decoded_input = []\n",
    "        \n",
    "        in0=[]\n",
    "        for idx in torch.squeeze(pair[0],0):\n",
    "            if idx.item() == EOW_token:\n",
    "                in0.append('<EOW>')\n",
    "                break\n",
    "            in0.append(input_lang.index2char[idx.item()])\n",
    "            \n",
    "        in1=[]\n",
    "        for idx in torch.squeeze(pair[1],0):\n",
    "            if idx.item() == EOW_token:\n",
    "                in1.append('<EOW>')\n",
    "                break\n",
    "            in1.append(output_lang.index2char[idx.item()])\n",
    "            \n",
    "        input_word = ''.join(decoded_input)\n",
    "        print('>', ''.join(in0))\n",
    "        print('=', ''.join(in1))\n",
    "        print('<', output_word)\n",
    "        print('')\n",
    "        showAttention(''.join(in0[0:-1]), output_chars, ''.join(in1[0:-1]), attentions[0, :len(output_chars), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8b050103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 3369 sentence pairs\n",
      "Counting chars...\n",
      "Counted chars:\n",
      "spa 31\n",
      "fre 39\n",
      "Epoch: 1/40,\tTime Taken: 6.96 seconds,\tTraining Loss: 1.3591,\tValidation Loss: 0.9789\n",
      "Epoch: 2/40,\tTime Taken: 6.09 seconds,\tTraining Loss: 0.9193,\tValidation Loss: 0.8144\n",
      "Epoch: 3/40,\tTime Taken: 6.28 seconds,\tTraining Loss: 0.7593,\tValidation Loss: 0.6431\n",
      "Epoch: 4/40,\tTime Taken: 6.62 seconds,\tTraining Loss: 0.5467,\tValidation Loss: 0.4409\n",
      "Epoch: 5/40,\tTime Taken: 6.12 seconds,\tTraining Loss: 0.3767,\tValidation Loss: 0.3178\n",
      "Epoch: 6/40,\tTime Taken: 6.80 seconds,\tTraining Loss: 0.2842,\tValidation Loss: 0.2587\n",
      "Epoch: 7/40,\tTime Taken: 6.35 seconds,\tTraining Loss: 0.2319,\tValidation Loss: 0.2248\n",
      "Epoch: 8/40,\tTime Taken: 7.25 seconds,\tTraining Loss: 0.2036,\tValidation Loss: 0.1997\n",
      "Epoch: 9/40,\tTime Taken: 9.78 seconds,\tTraining Loss: 0.1749,\tValidation Loss: 0.1816\n",
      "Epoch: 10/40,\tTime Taken: 10.77 seconds,\tTraining Loss: 0.1590,\tValidation Loss: 0.1769\n",
      "Epoch: 11/40,\tTime Taken: 12.41 seconds,\tTraining Loss: 0.1450,\tValidation Loss: 0.1788\n",
      "Epoch: 12/40,\tTime Taken: 7.15 seconds,\tTraining Loss: 0.1328,\tValidation Loss: 0.1580\n",
      "Epoch: 13/40,\tTime Taken: 7.86 seconds,\tTraining Loss: 0.1222,\tValidation Loss: 0.1623\n",
      "Epoch: 14/40,\tTime Taken: 7.69 seconds,\tTraining Loss: 0.1129,\tValidation Loss: 0.1472\n",
      "Epoch: 15/40,\tTime Taken: 7.83 seconds,\tTraining Loss: 0.1027,\tValidation Loss: 0.1476\n",
      "Epoch: 16/40,\tTime Taken: 7.30 seconds,\tTraining Loss: 0.0951,\tValidation Loss: 0.1485\n",
      "Epoch: 17/40,\tTime Taken: 6.45 seconds,\tTraining Loss: 0.0989,\tValidation Loss: 0.1461\n",
      "Epoch: 18/40,\tTime Taken: 6.68 seconds,\tTraining Loss: 0.0816,\tValidation Loss: 0.1425\n",
      "Epoch: 19/40,\tTime Taken: 7.25 seconds,\tTraining Loss: 0.0747,\tValidation Loss: 0.1382\n",
      "Epoch: 20/40,\tTime Taken: 7.61 seconds,\tTraining Loss: 0.0693,\tValidation Loss: 0.1417\n",
      "Epoch: 21/40,\tTime Taken: 7.10 seconds,\tTraining Loss: 0.0632,\tValidation Loss: 0.1351\n",
      "Epoch: 22/40,\tTime Taken: 7.68 seconds,\tTraining Loss: 0.0605,\tValidation Loss: 0.1387\n",
      "Epoch: 23/40,\tTime Taken: 7.39 seconds,\tTraining Loss: 0.0575,\tValidation Loss: 0.1542\n",
      "Validation loss has not gone down for 5 epochs. Implementing Early Stopping\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader, test_dataloader, test_data = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_chars, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_chars).to(device)\n",
    "\n",
    "train(train_dataloader, test_dataloader, encoder, decoder, 40, print_every=1, plot_every=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "def resume(model, filename):\n",
    "    model.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "819aa2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5364)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "def calculate_bleu_score(test_data):\n",
    "    bleu_score_candidate = []\n",
    "    bleu_score_reference = []\n",
    "    for pair in test_data:\n",
    "        pair = (torch.unsqueeze(pair[0], 0), torch.unsqueeze(pair[1], 0))\n",
    "        \n",
    "        output_chars, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        \n",
    "        in1 = []\n",
    "        for idx in torch.squeeze(pair[1], 0):\n",
    "            if idx.item() == EOW_token:\n",
    "                break\n",
    "            in1.append(output_lang.index2char[idx.item()])\n",
    "\n",
    "        ref_string = ''.join(in1)\n",
    "        candidate_string = ''.join(output_chars[:-1])\n",
    "\n",
    "        bleu_score_reference.append([ref_string])\n",
    "        bleu_score_candidate.append(candidate_string)\n",
    "        \n",
    "    bleu = BLEUScore(n_gram=1)\n",
    "    return bleu(bleu_score_candidate, bleu_score_reference)\n",
    "\n",
    "print(calculate_bleu_score(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "03e38186",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tfa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[425], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F1Score\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_f1_score_char_level\u001b[39m(test_data):\n\u001b[1;32m      4\u001b[0m     all_preds \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tfa'"
     ]
    }
   ],
   "source": [
    "from tfa.metrics import F1Score\n",
    "\n",
    "#Not working\n",
    "def calculate_f1_score_char_level(test_data):\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for pair in test_data:\n",
    "        input_seq, target_seq = torch.unsqueeze(pair[0], 0), torch.unsqueeze(pair[1], 0)\n",
    "\n",
    "        output_chars, _ = evaluate(encoder, decoder, input_seq, input_lang, output_lang)\n",
    "        \n",
    "        encoded_preds = [output_lang.char2index[char] for char in output_chars[:-1]]  # Assuming output_chars is a list of characters\n",
    "        encoded_targets = [output_lang.char2index[output_lang.index2char[idx.item()]] for idx in torch.squeeze(target_seq, 0) if (idx.item() != EOW_token) and idx.item() != SOW_token]\n",
    "\n",
    "        all_preds.append(encoded_preds)\n",
    "        all_targets.append(encoded_targets)\n",
    "\n",
    "    preds_tensor = torch.nn.utils.rnn.pad_sequence([torch.tensor(p, dtype=torch.int64) for p in all_preds], batch_first=True, padding_value=-100)\n",
    "    targets_tensor = torch.nn.utils.rnn.pad_sequence([torch.tensor(t, dtype=torch.int64) for t in all_targets], batch_first=True, padding_value=-100)\n",
    "\n",
    "    #f1 = F1Score(num_classes=len(output_lang.char2index), average='macro', ignore_index=-100, task='multiclass')\n",
    "\n",
    "    f1 = F1Score(num_classes=len(output_lang.char2index), average='marco', threshold=0.5)\n",
    "    \n",
    "    f1.update_state(preds_tensor, targets_tensor)\n",
    "\n",
    "    return f1.result()\n",
    "\n",
    "print(calculate_f1_score_char_level(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9120c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> kulto<EOW>\n",
      "= kylt<EOW>\n",
      "< kylt<EOW>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3633/2253724299.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + [*input_word] +\n",
      "/tmp/ipykernel_3633/2253724299.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + output_chars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> espektɾo<EOW>\n",
      "= spɛktʁ<EOW>\n",
      "< spɛktʁ<EOW>\n",
      "\n",
      "> akusasiones<EOW>\n",
      "= akyzasjɔ̃<EOW>\n",
      "< akysasjɔ̃<EOW>\n",
      "\n",
      "> aɾtifisialmente<EOW>\n",
      "= aʁtifisjɛləmɑ̃<EOW>\n",
      "< aʁtifisjɛləmɑ̃<EOW>\n",
      "\n",
      "> korexiɾ<EOW>\n",
      "= koʁiʒe<EOW>\n",
      "< koʁiʒe<EOW>\n",
      "\n",
      "> enkaɾnaɾ<EOW>\n",
      "= ɛ̃kaʁne<EOW>\n",
      "< ɑ̃kaʁne<EOW>\n",
      "\n",
      "> eskaneɾ<EOW>\n",
      "= skɑne<EOW>\n",
      "< skɑne<EOW>\n",
      "\n",
      "> baɾba<EOW>\n",
      "= baʁb<EOW>\n",
      "< vaʁb<EOW>\n",
      "\n",
      "> kwotas<EOW>\n",
      "= kota<EOW>\n",
      "< kota<EOW>\n",
      "\n",
      "> komunmente<EOW>\n",
      "= komynemɑ̃<EOW>\n",
      "< komynəmɑ̃<EOW>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
